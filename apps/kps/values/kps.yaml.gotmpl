grafana:
  enabled: false
  
prometheus:    
  ingress:
    enabled: false

  prometheusSpec:
    # To enable run this on the target namespace 
    # kubectl label ns NAMESPACE tonygilkerson.us/alerting=enabled
    ruleNamespaceSelector:
      matchLabels:
        tonygilkerson.us/alerting: enabled

    ## If true, a nil or {} value for prometheus.prometheusSpec.ruleSelector will cause the
    ## prometheus resource to be created with selectors based on values in the helm deployment,
    ## which will also match the PrometheusRule resources created
    ##
    ruleSelectorNilUsesHelmValues: false
    ## If {}, select all PrometheusRules
    ruleSelector: {}
    
    # To enable run this on the target namespace 
    # kubectl label ns NAMESPACE tonygilkerson.us/alerting=enabled
    serviceMonitorNamespaceSelector:
      matchLabels:
        tonygilkerson.us/alerting: enabled

    ## If true, a nil or {} value for prometheus.prometheusSpec.serviceMonitorSelector will cause the
    ## prometheus resource to be created with selectors based on values in the helm deployment,
    ## which will also match the servicemonitors created
    ##
    serviceMonitorSelectorNilUsesHelmValues: false

    # All serviceMonitors  
    ## If {}, select all ServiceMonitors
    serviceMonitorSelector: {}
     
    resources:
      limits: 
        cpu: 250m
        memory: 2048Mi
      requests:
        cpu: 250m
        memory: 2048Mi

alertmanager:
  enabled: true

  ingress:
    enabled: false 
  alertmanagerSpec:

    # To enable run this on the target namespace 
    # kubectl label ns NAMESPACE tonygilkerson.us/alerting=enabled
    alertmanagerConfigNamespaceSelector:
      matchLabels:
        tonygilkerson.us/alerting: enabled

    alertmanagerConfigSelector:
      matchLabels:
        tonygilkerson.us/alerting: enabled

# kube-state-metrics:
#   releaseLabel: false
#   customLabels:
#     foo: bar
